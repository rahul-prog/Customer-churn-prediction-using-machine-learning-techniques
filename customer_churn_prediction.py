# -*- coding: utf-8 -*-
"""churn final-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CnrO0kqYjRRLYCC3JZLjLeFTPxIHpja8
"""

import pandas as pd
import numpy as np
import random
import seaborn as sns
import matplotlib.pyplot as plt

dataset=pd.read_csv('new_churn.csv')
dataset.head()

ser=dataset['user']
dataset=dataset.drop(columns=['user'])
dataset.housing.value_counts()

dataset=pd.get_dummies(dataset)

dataset.columns

dataset=dataset.drop(columns=['housing_na','zodiac_sign_na','payment_type_na'])

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(dataset.drop(columns='churn'),dataset['churn'],test_size=0.2,random_state=0)

y_train.value_counts()

positive=y_train[y_train.values==1].index
negative=y_train[y_train.values==0].index
if len(positive)>len(negative):
    higher=positive
    lower=negative
else:
    lower=positive
    higher=negative
random.seed(0)
higher=np.random.choice(higher,size=len(lower))
lower=np.asarray(lower)
newindex=np.concatenate((lower,higher))

X_train=X_train.loc[newindex,]
y_train=y_train[newindex]

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train2=pd.DataFrame(sc.fit_transform(X_train))
X_test2=pd.DataFrame(sc.fit_transform(X_test))
X_train2.columns=X_train.columns.values
X_test.columns=X_test.columns.values
X_train2.index=X_train.index.values
X_test.index=X_test.index.values
X_train=X_train2
X_test=X_test2

X_train

from sklearn.linear_model import LogisticRegression
classifier=LogisticRegression(random_state=0)
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)
y_pred

from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score

cm=confusion_matrix(y_test,y_pred)
#accuracy_score(y_test,y_pred)

cm

accuracy_score(y_test,y_pred)

recall_score(y_test,y_pred)

f1_score(y_test,y_pred)



df=pd.DataFrame(cm,index=(0,1),columns=(0,1))
plt.figure(figsize=(15,10))
sns.set(font_scale=1.3)
sns.heatmap(df,annot=True,fmt='g')

from sklearn.model_selection import cross_val_score
acc=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)
acc

pd.concat([pd.DataFrame(X_train.columns,columns=["features"]),pd.DataFrame(np.transpose(classifier.coef_),columns=["coef"])]
   ,axis=1)

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

classifier=LogisticRegression()
X_train.shape

rf=RFE(classifier,25)

rf=rf.fit(X_train,y_train)

rf.support_

X_train.columns[rf.support_]

rf.ranking_

from sklearn.linear_model import LogisticRegression
classifier=LogisticRegression(random_state=0)
classifier.fit(X_train[X_train.columns[rf.support_]],y_train)
y_pred=classifier.predict(X_test[X_test.columns[rf.support_]])
y_pred

from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score

cm=confusion_matrix(y_test,y_pred)
cm

accuracy_score(y_test,y_pred)

user_identifier='churn'
final=pd.concat([y_test,ser],axis=1).dropna()
final['predicted_value']=y_pred
final=final[['user','churn','predicted_value']].reset_index(drop='True')
final

from sklearn.svm import LinearSVC
svm = LinearSVC()
svm.fit(X_train,y_train)

y_pred = svm.predict(X_test)
y_pred

accuracy_score(y_test,y_pred)









































